{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with Ensemble Method: Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will try out a few iterations of **Bagging algorithm** and see which parameters and features maximize our **Class 2 recall score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report, recall_score, make_scorer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(os.pardir, os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "#import customized functions\n",
    "from src.data_cleaning import cleaning_functions as cfs\n",
    "from src.data_cleaning import exploration_functions as efs\n",
    "from src.data_cleaning import processing_functions as pfs\n",
    "from src.data_cleaning import modeling_functions as mfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, classes_dict = pfs.processed_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = pfs.ohe_train_and_test_features(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = mfs.scorer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's checkout our class distribution again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.544310\n",
       "2    0.384646\n",
       "1    0.071044\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using **SMOTE** and fixing this imbalance first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_smoted, y_train_smoted = SMOTE(random_state=2020).fit_sample(X_train.values, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    24249\n",
       "1    24249\n",
       "0    24249\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_smoted.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We shall use both the unsmoted and smoted sets for our modeling purposes from here on...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Starting our modeling with BaggingClassifier\n",
    "\n",
    ">A Bagging classifier is an ensemble meta-estimator that fits base classifiers each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction. Such a meta-estimator can typically be used as a way to reduce the variance of a black-box estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(random_state=2020)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating a BaggingClassifier\n",
    "bagc = BaggingClassifier(random_state=2020)\n",
    "bagc.fit(X_train_smoted, y_train_smoted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75132995, 0.73611283, 0.56625015])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(bagc, X_train_smoted, y_train_smoted, scoring=scorer, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall score of class 2 about 70% for two out of the three folds, not a totally awful start let's keep at it.\n",
    "We'll change a few parameters and see if it changes.\n",
    "\n",
    "Let's first compare it with un-smoted & weight-balanced data and see if it does anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Class 2 recall score : \n",
      " [0.7359944  0.73564426 0.73897059]\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=2020, class_weight='balanced')\n",
    "bagc2 = BaggingClassifier(dt, random_state=2020)\n",
    "bagc2.fit(X_train, y_train)\n",
    "print('New Class 2 recall score :','\\n',cross_val_score(bagc2, X_train, y_train, scoring=scorer, cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow that was more consistent across these folds ---interesting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try changing the parameters, I will first try a grid search, if it takes toooo long I'll start tuning the hyperparameters manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining param grid.\n",
    "param_grid = {\n",
    "    'n_estimators': [20, 50, 80],\n",
    "    'max_samples': [5, 15, 20]\n",
    "}\n",
    "\n",
    "# Initializing gridsearch with 3-fold cross-validation.\n",
    "gs = GridSearchCV(estimator=bagc2, param_grid=param_grid, cv=3, scoring=scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight='balanced',\n",
       "                                                                               random_state=2020),\n",
       "                                         random_state=2020),\n",
       "             param_grid={'max_samples': [5, 15, 20],\n",
       "                         'n_estimators': [20, 50, 80]},\n",
       "             scoring=make_scorer(class_2_recall))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5106792717086834"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score it.\n",
    "gs.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hmmm.... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_samples': 15, 'n_estimators': 20}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6046918767507002"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight='balanced',\n",
       "                                                        random_state=2020),\n",
       "                  max_samples=15, n_estimators=20, random_state=2020)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying cross valdiation with newly discovered `best_estimator_` on `un-smoted dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 2 Recall Score: \n",
      " [0.5852591  0.60696779 0.62184874]\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=2020, class_weight='balanced')\n",
    "bagc3 = BaggingClassifier(base_estimator=dt, max_samples= 15, n_estimators= 20, random_state=2020)\n",
    "bagc3.fit(X_train, y_train)\n",
    "print('Class 2 Recall Score:','\\n',cross_val_score(bagc3, X_train, y_train, scoring=scorer, cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unimpressive across the board, giving it one more go with the `smoted dataset` knowing these best estimators were discovered from unsmoted dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 2 Recall Score: \n",
      " [0.34813807 0.51193864 0.41346035]\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=2020)\n",
    "bagc4 = BaggingClassifier(base_estimator=dt, max_samples= 15, n_estimators= 20, random_state=2020)\n",
    "bagc4.fit(X_train_smoted, y_train_smoted)\n",
    "print('Class 2 Recall Score:','\\n',cross_val_score(bagc3, X_train_smoted, y_train_smoted, scoring=scorer, cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As imagined, didn't get any better\n",
    "\n",
    "#### Wondering if there's anything else we could do to get a better score.... \n",
    "will try changing a few more hyperparameters before moving on to the next ensemble method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 2 Recall Score: \n",
      " [0.34733894 0.43434874 0.52538515]\n"
     ]
    }
   ],
   "source": [
    "#Unsmoted dataset\n",
    "dt = DecisionTreeClassifier(random_state=2020, class_weight='balanced')\n",
    "bagc5 = BaggingClassifier(base_estimator=dt, max_samples= 20, n_estimators= 100, random_state=2020)\n",
    "bagc5.fit(X_train, y_train)\n",
    "print('Class 2 Recall Score:','\\n',cross_val_score(bagc5, X_train, y_train, scoring=scorer, cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 2 Recall Score: \n",
      " [0.46022516 0.63973772 0.60336509]\n"
     ]
    }
   ],
   "source": [
    "#smoted dataset\n",
    "dt = DecisionTreeClassifier(random_state=2020)\n",
    "bagc6 = BaggingClassifier(base_estimator=dt, max_samples= 20, n_estimators= 100, random_state=2020)\n",
    "bagc6.fit(X_train_smoted, y_train_smoted)\n",
    "print('Class 2 Recall Score:','\\n',cross_val_score(bagc6, X_train_smoted, y_train_smoted, scoring=scorer, cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**just can't catch a break with this model...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try out our test set with the best performer in this lot `bagc2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.740857946554149"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, bagc2.predict(X_test), average=None)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Not too bad!!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moving on to Random Forest --- Next Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Tanzania)",
   "language": "python",
   "name": "tanzania"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
