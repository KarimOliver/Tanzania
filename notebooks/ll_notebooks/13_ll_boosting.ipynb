{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with Ensemble Method: Boosting\n",
    "\n",
    "In this notebook I will try out a few iterations of **Boosting algorithm** one last time and see which parameters and features maximize our **Class 2 recall score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report, recall_score, make_scorer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(os.pardir, os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "#import customized functions\n",
    "from src.data_cleaning import cleaning_functions as cfs\n",
    "from src.data_cleaning import exploration_functions as efs\n",
    "from src.data_cleaning import processing_functions as pfs\n",
    "from src.data_cleaning import modeling_functions as mfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, classes_dict = pfs.processed_dataset()\n",
    "X_train, X_test = pfs.ohe_train_and_test_features(X_train, X_test)\n",
    "scorer = mfs.scorer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_smoted, y_train_smoted = SMOTE(random_state=2020).fit_sample(X_train.values, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting Algorithm\n",
    "\n",
    "> The fundamental idea of boosting is to start with a weak learner and then to use information about its errors to build a new model that can supplement the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 2 recall score : \n",
      " [0.59121148 0.61116947 0.61677171]\n"
     ]
    }
   ],
   "source": [
    "# Instantiating a BoostingClassifier\n",
    "dt = DecisionTreeClassifier(random_state=2020, class_weight='balanced')\n",
    "abc1 = AdaBoostClassifier(random_state=2020)\n",
    "abc1.fit(X_train, y_train)\n",
    "print('Class 2 recall score :','\\n',cross_val_score(abc1, X_train, y_train, scoring=scorer, cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to have high bias (we've been getting a recall score of about 77%). Let's try it out on smoted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 2 recall score : \n",
      " [0.59507609 0.61796363 0.4469875 ]\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=2020)\n",
    "abc2 = AdaBoostClassifier(random_state=2020)\n",
    "abc2.fit(X_train_smoted, y_train_smoted)\n",
    "print('Class 2 recall score :','\\n',cross_val_score(abc2, X_train_smoted, y_train_smoted, scoring=scorer, cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not good either, will try increasingt the n_estimators and give it a go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 2 recall score : \n",
      " [0.6547619  0.65791317 0.67436975]\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=2020, class_weight='balanced')\n",
    "abc1 = AdaBoostClassifier(random_state=2020, n_estimators=200)\n",
    "abc1.fit(X_train, y_train)\n",
    "print('Class 2 recall score :','\\n',cross_val_score(abc1, X_train, y_train, scoring=scorer, cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to `abc1` low variance but high bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of Adaptive Boosting let's try out Gradient Boosting and see if that helps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 2 recall score : \n",
      " [0.62027311 0.6285014  0.63707983]\n"
     ]
    }
   ],
   "source": [
    "# Instantiating a BoostingClassifier\n",
    "gbc1 = GradientBoostingClassifier(random_state=2020)\n",
    "gbc1.fit(X_train, y_train)\n",
    "print('Class 2 recall score :','\\n',cross_val_score(gbc1, X_train, y_train, scoring=scorer, cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc1.n_estimators_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one took tooo long to run and the recall scores are just bleh, not worth our time or trouble. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/lulualakdawala/Documents/DS_course/Mod_3/project/Tanzania/notebooks/ll_notebooks',\n",
       " '/opt/anaconda3/lib/python37.zip',\n",
       " '/opt/anaconda3/lib/python3.7',\n",
       " '/opt/anaconda3/lib/python3.7/lib-dynload',\n",
       " '',\n",
       " '/opt/anaconda3/lib/python3.7/site-packages',\n",
       " '/opt/anaconda3/lib/python3.7/site-packages/aeosa',\n",
       " '/opt/anaconda3/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/Users/lulualakdawala/.ipython',\n",
       " '/Users/lulualakdawala/Documents/DS_course/Mod_3/project/Tanzania']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Tanzania)",
   "language": "python",
   "name": "tanzania"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
